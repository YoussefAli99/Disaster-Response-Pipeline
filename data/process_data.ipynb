{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our necessary libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(messages_filepath, categories_filepath):\n",
    "    \"\"\"\n",
    "    This function serves to load our datasets to the pandas DataFrame\n",
    "    \n",
    "    INPUT -> messages and categories filepath astype(str)\n",
    "    OUTPUT -> returns a merged DataFrame\n",
    "    \"\"\"\n",
    "    # load messages dataset\n",
    "    messages = pd.read_csv(messages_filepath)\n",
    "    # load categories dataset\n",
    "    categories = pd.read_csv(categories_filepath)\n",
    "    # merge datasets\n",
    "    df = messages.merge(categories, on='id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    This function takes our dataframe that needs to be cleaned\n",
    "    \n",
    "    INPUT ->  astype(pd.DataFrame)\n",
    "    OUTPUT -> The DataFrame cleaned\n",
    "    \"\"\"\n",
    "    # create a dataframe of the n individual category columns\n",
    "    categories = df['categories'].str.split(';', expand=True)\n",
    "    row = next(categories.iterrows())[1]\n",
    "    category_colnames = pd.Series(row).apply(lambda x: x[:-2])\n",
    "    categories.columns = category_colnames\n",
    "    \n",
    "    for column in categories.columns:\n",
    "        # set each value to be the last character of the string and transfer it to numeric\n",
    "        categories[column] = categories[column].apply(lambda x: int(x[-1]))\n",
    "    \n",
    "    # drop the original categories column from `df`\n",
    "    df.drop('categories', axis=1, inplace=True)\n",
    "    # concatenate the original dataframe with the new `categories` dataframe\n",
    "    df = pd.concat([df, categories], axis=1)\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(keep='first', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, database_filename):\n",
    "    \"\"\"\n",
    "    save_data function saves the dataframe in a sqlite database\n",
    "    \n",
    "    INPUT -> pd.DataFrame, database_filename astype(str)\n",
    "    OUTPUT -> This function has no output\n",
    "    \"\"\"\n",
    "    engine = create_engine('sqlite:///'+ database_filename)\n",
    "    df.to_sql('messages', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    This main function will execute the ETL pipeline:\n",
    "    1- Extraact out data from datasets\n",
    "    2- Transform our data to 'clean_data'\n",
    "    3- Load the cleaned dataframe into a sqlite database \n",
    "        \n",
    "    \"\"\"\n",
    "    if len(sys.argv) == 4:\n",
    "\n",
    "        messages_filepath, categories_filepath, database_filepath = sys.argv[1:]\n",
    "\n",
    "        print('Loading data...\\n    MESSAGES: {}\\n    CATEGORIES: {}'\n",
    "              .format(messages_filepath, categories_filepath))\n",
    "        df = load_data(messages_filepath, categories_filepath)\n",
    "\n",
    "        print('Cleaning data...')\n",
    "        df = clean_data(df)\n",
    "        \n",
    "        print('Saving data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "        save_data(df, database_filepath)\n",
    "        \n",
    "        print('Cleaned data saved to database!')\n",
    "    \n",
    "    else:\n",
    "        print('Please provide the filepaths of the messages and categories '\\\n",
    "              'datasets as the first and second argument respectively, as '\\\n",
    "              'well as the filepath of the database to save the cleaned data '\\\n",
    "              'to as the third argument. \\n\\nExample: python process_data.py '\\\n",
    "              'disaster_messages.csv disaster_categories.csv '\\\n",
    "              'DisasterResponse.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the filepaths of the messages and categories datasets as the first and second argument respectively, as well as the filepath of the database to save the cleaned data to as the third argument. \n",
      "\n",
      "Example: python process_data.py disaster_messages.csv disaster_categories.csv DisasterResponse.db\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
